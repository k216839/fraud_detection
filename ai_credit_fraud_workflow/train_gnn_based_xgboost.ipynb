{"cells":[{"cell_type":"markdown","metadata":{"id":"ZeWhQb4j3WJ7"},"source":["## Train a GNN-based XGBoost Model\n","#### Goals\n","* Train a GNN (GraphSAGE) model that produces node (transaction) embeddings.\n","* Use these node embeddings to train an XGBoost model.\n","* Save the trained GNN and XGBoost models for inference.\n","\n","__Prerequisite__: The preprocessing notebook must be executed before running this notebook."]},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"znZ98mkv3bxc","executionInfo":{"status":"ok","timestamp":1747296672104,"user_tz":-420,"elapsed":12,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# !cp -r /content/drive/MyDrive/VNPT/data.zip /content/"],"metadata":{"id":"NisjbV6w3i9E","executionInfo":{"status":"ok","timestamp":1747296672131,"user_tz":-420,"elapsed":25,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# import zipfile\n","# zip_file = 'data.zip'\n","# with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n","#     zip_ref.extractall()"],"metadata":{"id":"81kjbHPK3udV","executionInfo":{"status":"ok","timestamp":1747296672145,"user_tz":-420,"elapsed":27,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HsgEiXjE3WJ9"},"source":["#### Dataset names"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"DoxgbzW43WJ9","executionInfo":{"status":"ok","timestamp":1747296672164,"user_tz":-420,"elapsed":18,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["# Name of the datasets to choose from\n","TABFORMER = \"TabFormer\"\n","SPARKOV = \"Sparkov\""]},{"cell_type":"markdown","metadata":{"id":"I9pweNqQ3WJ-"},"source":["### Select the dataset to train the models on"]},{"cell_type":"markdown","metadata":{"id":"aJMJgcV33WJ-"},"source":["__Note__:  This notebook works for both __TabFormer__ and __Sparkov__ dataset.\n","Make sure that the right dataset is selected.\n","For yhe TabFormer dataset, set\n","\n","```code\n","    DATASET = TABFORMER\n","```\n","and for the Sparkov dataset, set\n","\n","```code\n","    DATASET = SPARKOV\n","```"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"hUBAbUBl3WJ_","executionInfo":{"status":"ok","timestamp":1747296672222,"user_tz":-420,"elapsed":71,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["# Change this to either TABFORMER or SPARKOV\n","DATASET = TABFORMER"]},{"cell_type":"markdown","metadata":{"id":"eV04oCmd3WJ_"},"source":["\n","#### Import necessary libraries, packages, and functions"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"OUlkjXZu3WJ_","executionInfo":{"status":"ok","timestamp":1747296681888,"user_tz":-420,"elapsed":9690,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["# General-purpose libraries and OS handling\n","import os\n","from typing import Tuple, Dict\n","import json\n","from collections import defaultdict\n","\n","# GPU-accelerated libraries (torch, cupy, cudf, rmm)\n","import torch\n","import cupy\n","import cudf\n","import rmm\n","from rmm.allocators.cupy import rmm_cupy_allocator\n","from rmm.allocators.torch import rmm_torch_allocator\n","\n","# Reinitialize RMM and set allocators to manage memory efficiently on GPU\n","rmm.reinitialize(devices=[0], pool_allocator=True, managed_memory=True)\n","cupy.cuda.set_allocator(rmm_cupy_allocator)\n","torch.cuda.memory.change_current_allocator(rmm_torch_allocator)"]},{"cell_type":"code","source":["!pip install cugraph-pyg-cu12 --extra-index-url=https://pypi.nvidia.com"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5qKrCWhE4Akl","executionInfo":{"status":"ok","timestamp":1747296684861,"user_tz":-420,"elapsed":2992,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}},"outputId":"b95daf86-8a21-4442-a3f4-a181c83dc7fe"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n","Requirement already satisfied: cugraph-pyg-cu12 in /usr/local/lib/python3.11/dist-packages (25.4.2)\n","Requirement already satisfied: cugraph-cu12==25.4.* in /usr/local/lib/python3.11/dist-packages (from cugraph-pyg-cu12) (25.4.1)\n","Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.11/dist-packages (from cugraph-pyg-cu12) (0.60.0)\n","Requirement already satisfied: numpy<3.0a0,>=1.23 in /usr/local/lib/python3.11/dist-packages (from cugraph-pyg-cu12) (2.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from cugraph-pyg-cu12) (2.2.2)\n","Requirement already satisfied: torch-geometric<2.7,>=2.5 in /usr/local/lib/python3.11/dist-packages (from cugraph-pyg-cu12) (2.6.1)\n","Requirement already satisfied: cuda-python<13.0a0,>=12.6.2 in /usr/local/lib/python3.11/dist-packages (from cugraph-cu12==25.4.*->cugraph-pyg-cu12) (12.6.2.post1)\n","Requirement already satisfied: cudf-cu12==25.4.* in /usr/local/lib/python3.11/dist-packages (from cugraph-cu12==25.4.*->cugraph-pyg-cu12) (25.4.0)\n","Requirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from cugraph-cu12==25.4.*->cugraph-pyg-cu12) (13.3.0)\n","Requirement already satisfied: dask-cuda==25.4.* in /usr/local/lib/python3.11/dist-packages (from cugraph-cu12==25.4.*->cugraph-pyg-cu12) (25.4.0)\n","Requirement already satisfied: dask-cudf-cu12==25.4.* in /usr/local/lib/python3.11/dist-packages (from cugraph-cu12==25.4.*->cugraph-pyg-cu12) (25.4.0)\n","Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=0.6.0->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (2025.3.2)\n","Requirement already satisfied: libcugraph-cu12==25.4.* in /usr/local/lib/python3.11/dist-packages (from cugraph-cu12==25.4.*->cugraph-pyg-cu12) (25.4.1)\n","Requirement already satisfied: pylibcugraph-cu12==25.4.* in /usr/local/lib/python3.11/dist-packages (from cugraph-cu12==25.4.*->cugraph-pyg-cu12) (25.4.1)\n","Requirement already satisfied: pylibraft-cu12==25.4.* in /usr/local/lib/python3.11/dist-packages (from cugraph-cu12==25.4.*->cugraph-pyg-cu12) (25.4.0)\n","Requirement already satisfied: raft-dask-cu12==25.4.* in /usr/local/lib/python3.11/dist-packages (from cugraph-cu12==25.4.*->cugraph-pyg-cu12) (25.4.0)\n","Requirement already satisfied: rapids-dask-dependency==25.4.* in /usr/local/lib/python3.11/dist-packages (from cugraph-cu12==25.4.*->cugraph-pyg-cu12) (25.4.0)\n","Requirement already satisfied: rmm-cu12==25.4.* in /usr/local/lib/python3.11/dist-packages (from cugraph-cu12==25.4.*->cugraph-pyg-cu12) (25.4.0)\n","Requirement already satisfied: ucx-py-cu12==0.43.* in /usr/local/lib/python3.11/dist-packages (from cugraph-cu12==25.4.*->cugraph-pyg-cu12) (0.43.0)\n","Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (5.5.2)\n","Requirement already satisfied: libcudf-cu12==25.4.* in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (25.4.0)\n","Requirement already satisfied: numba-cuda<0.5.0a0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (0.4.0)\n","Requirement already satisfied: nvtx>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (0.2.11)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (24.2)\n","Requirement already satisfied: pyarrow<20.0.0a0,>=14.0.0 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (18.1.0)\n","Requirement already satisfied: pylibcudf-cu12==25.4.* in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (25.4.0)\n","Requirement already satisfied: pynvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (0.6.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (13.9.4)\n","Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (4.13.2)\n","Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask-cuda==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (8.1.8)\n","Requirement already satisfied: pynvml<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from dask-cuda==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (12.0.0)\n","Requirement already satisfied: zict>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from dask-cuda==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (3.0.0)\n","Requirement already satisfied: libraft-cu12==25.4.* in /usr/local/lib/python3.11/dist-packages (from libcugraph-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (25.4.0)\n","Requirement already satisfied: distributed-ucxx-cu12==0.43.* in /usr/local/lib/python3.11/dist-packages (from raft-dask-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (0.43.0)\n","Requirement already satisfied: dask==2025.2.0 in /usr/local/lib/python3.11/dist-packages (from rapids-dask-dependency==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (2025.2.0)\n","Requirement already satisfied: distributed==2025.2.0 in /usr/local/lib/python3.11/dist-packages (from rapids-dask-dependency==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (2025.2.0)\n","Requirement already satisfied: librmm-cu12==25.4.* in /usr/local/lib/python3.11/dist-packages (from rmm-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (25.4.0)\n","Requirement already satisfied: libucx-cu12<1.19,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from ucx-py-cu12==0.43.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (1.18.1)\n","Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (3.1.1)\n","Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (1.4.2)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (6.0.2)\n","Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (0.12.1)\n","Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (8.7.0)\n","Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.11/dist-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (3.1.6)\n","Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (1.0.0)\n","Requirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (1.1.0)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (5.9.5)\n","Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.11/dist-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (2.4.0)\n","Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (3.1.0)\n","Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (6.4.2)\n","Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.11/dist-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (2.4.0)\n","Requirement already satisfied: ucxx-cu12==0.43.* in /usr/local/lib/python3.11/dist-packages (from distributed-ucxx-cu12==0.43.*->raft-dask-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (0.43.0)\n","Requirement already satisfied: libkvikio-cu12==25.4.* in /usr/local/lib/python3.11/dist-packages (from libcudf-cu12==25.4.*->cudf-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (25.4.0)\n","Requirement already satisfied: nvidia-nvcomp-cu12==4.2.0.11 in /usr/local/lib/python3.11/dist-packages (from libcudf-cu12==25.4.*->cudf-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (4.2.0.11)\n","Requirement already satisfied: rapids-logger==0.1.* in /usr/local/lib/python3.11/dist-packages (from libcudf-cu12==25.4.*->cudf-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (0.1.1)\n","Requirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.4.*->libcugraph-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (12.4.5.8)\n","Requirement already satisfied: nvidia-curand-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.4.*->libcugraph-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.4.*->libcugraph-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.4.*->libcugraph-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (12.3.1.170)\n","Requirement already satisfied: libucxx-cu12==0.43.* in /usr/local/lib/python3.11/dist-packages (from ucxx-cu12==0.43.*->distributed-ucxx-cu12==0.43.*->raft-dask-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (0.43.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57->cugraph-pyg-cu12) (0.43.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->cugraph-pyg-cu12) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->cugraph-pyg-cu12) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->cugraph-pyg-cu12) (2025.2)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric<2.7,>=2.5->cugraph-pyg-cu12) (3.11.15)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric<2.7,>=2.5->cugraph-pyg-cu12) (3.2.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric<2.7,>=2.5->cugraph-pyg-cu12) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric<2.7,>=2.5->cugraph-pyg-cu12) (4.67.1)\n","Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x>=12.0.0->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (0.8.3)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric<2.7,>=2.5->cugraph-pyg-cu12) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric<2.7,>=2.5->cugraph-pyg-cu12) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric<2.7,>=2.5->cugraph-pyg-cu12) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric<2.7,>=2.5->cugraph-pyg-cu12) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric<2.7,>=2.5->cugraph-pyg-cu12) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric<2.7,>=2.5->cugraph-pyg-cu12) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric<2.7,>=2.5->cugraph-pyg-cu12) (1.20.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.10.3->distributed==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (3.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->cugraph-pyg-cu12) (1.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric<2.7,>=2.5->cugraph-pyg-cu12) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric<2.7,>=2.5->cugraph-pyg-cu12) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric<2.7,>=2.5->cugraph-pyg-cu12) (2025.4.26)\n","Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pynvml<13.0.0a0,>=12.0.0->dask-cuda==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (12.575.51)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->cudf-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->cudf-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (2.19.1)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (3.21.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->cudf-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (0.1.2)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12->libraft-cu12==25.4.*->libcugraph-cu12==25.4.*->cugraph-cu12==25.4.*->cugraph-pyg-cu12) (12.4.127)\n"]}]},{"cell_type":"code","source":["!pip show cugraph-pyg-cu12"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OTgz3bOH-YEk","executionInfo":{"status":"ok","timestamp":1747296687482,"user_tz":-420,"elapsed":2620,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}},"outputId":"70638820-0107-46c9-a5c5-dd31c9f98a32"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: cugraph-pyg-cu12\n","Version: 25.4.2\n","Summary: cugraph-pyg - PyG support for cuGraph massive-scale, ultra-fast GPU graph analytics.\n","Home-page: https://github.com/rapidsai/cugraph\n","Author: NVIDIA Corporation\n","Author-email: \n","License: Apache 2.0\n","Location: /usr/local/lib/python3.11/dist-packages\n","Requires: cugraph-cu12, numba, numpy, pandas, torch-geometric\n","Required-by: \n"]}]},{"cell_type":"code","source":["!pip show torch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IvIXOC7--tIV","executionInfo":{"status":"ok","timestamp":1747296689504,"user_tz":-420,"elapsed":2020,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}},"outputId":"6ee399d7-8838-48d1-ed84-2aa4e00987d2"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: torch\n","Version: 2.6.0+cu124\n","Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n","Home-page: https://pytorch.org/\n","Author: PyTorch Team\n","Author-email: packages@pytorch.org\n","License: BSD-3-Clause\n","Location: /usr/local/lib/python3.11/dist-packages\n","Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-cusparselt-cu12, nvidia-nccl-cu12, nvidia-nvjitlink-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n","Required-by: accelerate, fastai, peft, sentence-transformers, tensordict, timm, torchaudio, torchdata, torchvision\n"]}]},{"cell_type":"code","source":["# PyTorch and related libraries\n","import torch.nn.functional as F\n","import torch.nn as nn\n","\n","# PyTorch Geometric and cuGraph libraries for GNNs and graph handling\n","import cugraph_pyg\n","from cugraph_pyg.loader import NeighborLoader\n","import torch_geometric\n","from torch_geometric.nn import SAGEConv\n","\n","# Enable GPU memory spilling to CPU with cuDF to handle larger datasets\n","from cugraph.testing.mg_utils import enable_spilling  # noqa: E402\n","enable_spilling()\n","\n","# XGBoost for machine learning model building\n","import xgboost as xgb\n","\n","# Numerical operations with cupy and numpy\n","import cupy as cp\n","import numpy as np\n","\n","# Machine learning metrics from sklearn\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vFEJooa53_PW","executionInfo":{"status":"ok","timestamp":1747296700210,"user_tz":-420,"elapsed":10693,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}},"outputId":"461bb3b2-7472-4a1a-b892-7060eb77fe26"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/tensordict/_pytree.py:93: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n","  _register_pytree_node(\n"]}]},{"cell_type":"markdown","metadata":{"id":"mSnsfWPE3WKA"},"source":["#### Some config parameters for neighborhood sampler and training"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"mwseKL943WKA","executionInfo":{"status":"ok","timestamp":1747296700230,"user_tz":-420,"elapsed":18,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["args = type('', (), {})()\n","\n","args.out_channels = 2\n","args.batch_size = 1024\n","args.fan_out = 10\n","args.use_cross_weights = True\n","args.cross_weights = None"]},{"cell_type":"markdown","metadata":{"id":"j0NvNJ223WKA"},"source":["##### Path to pre-processed data and directory to save models"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"MV_51Rnm3WKA","executionInfo":{"status":"ok","timestamp":1747296700245,"user_tz":-420,"elapsed":14,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["dateset_name_to_path= defaultdict(lambda: \"./data/TabFormer\")\n","\n","dateset_name_to_path['TabFormer'] = './data/TabFormer'\n","dateset_name_to_path['Sparkov'] = './data/Sparkov'\n","args.dataset_base_path = dateset_name_to_path[DATASET]\n","\n","args.dataset_root = os.path.join(args.dataset_base_path, 'gnn')\n","args.model_root_dir = os.path.join(args.dataset_base_path, 'models')"]},{"cell_type":"markdown","metadata":{"id":"atkn3kiE3WKB"},"source":["#### Read number of transactions nodes that was saved during preprocessing"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MLbAwoMW3WKB","executionInfo":{"status":"ok","timestamp":1747296700264,"user_tz":-420,"elapsed":18,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}},"outputId":"09fc0ec7-0ab0-4fe1-9cf6-a721f76f6d21"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["280988"]},"metadata":{},"execution_count":13}],"source":["# Number of transactions nodes were saved in variables.json during training\n","with open(os.path.join(args.dataset_base_path, 'variables.json'), 'r') as json_file:\n","    num_transaction_nodes = json.load(json_file)['NUM_TRANSACTION_NODES']\n","\n","num_transaction_nodes"]},{"cell_type":"markdown","metadata":{"id":"1sLIp95x3WKB"},"source":["#### Define a GraphSAGE model"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"9IKBMrT13WKB","executionInfo":{"status":"ok","timestamp":1747296700308,"user_tz":-420,"elapsed":42,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["class GraphSAGE(torch.nn.Module):\n","    \"\"\"\n","    GraphSAGE model for graph-based learning.\n","\n","    This model learns node embeddings by aggregating information from a node's\n","    neighborhood using multiple graph convolutional layers.\n","\n","    Parameters:\n","    ----------\n","    in_channels : int\n","        The number of input features for each node.\n","    hidden_channels : int\n","        The number of hidden units in each layer, controlling the embedding dimension.\n","    out_channels : int\n","        The number of output features (or classes) for the final layer.\n","    n_hops : int\n","        The number of GraphSAGE layers (or hops) used to aggregate information\n","        from neighboring nodes.\n","    dropout_prob : float, optional (default=0.25)\n","        The probability of dropping out nodes during training for regularization.\n","    \"\"\"\n","    def __init__(self, in_channels, hidden_channels, out_channels, n_hops, dropout_prob=0.25):\n","        super(GraphSAGE, self).__init__()\n","\n","        # list of conv layers\n","        self.convs = nn.ModuleList()\n","        # add first conv layer to the list\n","        self.convs.append(SAGEConv(in_channels, hidden_channels))\n","        # add the remaining conv layers to the list\n","        for _ in range(n_hops - 1):\n","            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n","\n","        # output layer\n","        self.fc = nn.Linear(hidden_channels, out_channels)\n","\n","    def forward(self, x, edge_index, return_hidden=False):\n","\n","        for conv in self.convs:\n","            x = conv(x, edge_index)\n","            x = F.relu(x)\n","            x = F.dropout(x, p=0.5, training=self.training)\n","\n","        if return_hidden:\n","            return x\n","        else:\n","            return self.fc(x)"]},{"cell_type":"markdown","metadata":{"id":"0iYeBf0F3WKB"},"source":["\n","#### Define a function to train the GraphSAGE model\n","__Note__: This function is called a few times if grid search is used to find better hyper-parameters."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"R_Rrn_7Y3WKB","executionInfo":{"status":"ok","timestamp":1747296700326,"user_tz":-420,"elapsed":17,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["def train_gnn(model, loader, optimizer, criterion)->float:\n","    \"\"\"\n","    Trains the GraphSAGE model for one epoch.\n","\n","    Parameters:\n","    ----------\n","    model : torch.nn.Module\n","        The GNN model to be trained.\n","    loader : tcugraph_pyg.loader.NeighborLoader\n","        DataLoader that provides batches of graph data for training.\n","    optimizer : torch.optim.Optimizer\n","        Optimizer used to update the model's parameters.\n","    criterion : torch.nn.Module\n","        Loss function used to calculate the difference between predictions and targets.\n","\n","    Returns:\n","    -------\n","    float\n","        The average training loss over all batches for this epoch.\n","    \"\"\"\n","    model.train()\n","    total_loss = 0\n","    batch_count = 0\n","    for batch in loader:\n","        batch_count += 1\n","        optimizer.zero_grad()\n","\n","        batch_size = batch.batch_size\n","        out = model(batch.x[:,:].to(torch.float32), batch.edge_index)[:batch_size]\n","        y = batch.y[:batch_size].view(-1).to(torch.long)\n","        loss = criterion(out, y)\n","        loss.backward()\n","\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / batch_count\n"]},{"cell_type":"markdown","metadata":{"id":"DhtUe17K3WKB"},"source":["\n","\n","#### Define a function to extract node (transaction) embeddings from the second-to-last layer of the GraphSAGE model\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Al-m8J7v3WKB","executionInfo":{"status":"ok","timestamp":1747296700344,"user_tz":-420,"elapsed":16,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["def extract_embeddings(model, loader)->Tuple[torch.Tensor, torch.Tensor]:\n","    \"\"\"\n","    Extracts node embeddings produced by the GraphSAGE model.\n","\n","    Parameters:\n","    ----------\n","    model : torch.nn.Module\n","        The model used to generate embeddings, typically a pre-trained neural network.\n","    loader : cugraph_pyg.loader.NeighborLoader\n","        NeighborLoader that provides batches of data for embedding extraction.\n","\n","    Returns:\n","    -------\n","    Tuple[torch.Tensor, torch.Tensor]\n","        A tuple containing two tensors:\n","        - embeddings: A tensor containing embeddings for each input sample in the dataset.\n","        - labels: A tensor containing the corresponding labels for each sample.\n","    \"\"\"\n","    model.eval()\n","    embeddings = []\n","    labels = []\n","    with torch.no_grad():\n","        for batch in loader:\n","            batch_size = batch.batch_size\n","            hidden = model(batch.x[:,:].to(torch.float32), batch.edge_index, return_hidden=True)[:batch_size]\n","            embeddings.append(hidden)  # Keep embeddings on GPU\n","            labels.append(batch.y[:batch_size].view(-1).to(torch.long))\n","    embeddings = torch.cat(embeddings, dim=0)  # Concatenate embeddings on GPU\n","    labels = torch.cat(labels, dim=0)  # Concatenate labels on GPU\n","    return embeddings, labels"]},{"cell_type":"markdown","metadata":{"id":"NqOJQWx63WKC"},"source":["\n","#### Define a function to evaluate the GraphSAGE model\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"0mwWsmTE3WKC","executionInfo":{"status":"ok","timestamp":1747296700378,"user_tz":-420,"elapsed":32,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["def evaluate_gnn(model, loader) -> float:\n","    \"\"\"\n","    Evaluates the performance of the GraphSAGE model.\n","\n","    Parameters:\n","    ----------\n","    model : torch.nn.Module\n","        The GNN model to be evaluated.\n","    loader : cugraph_pyg.loader.NeighborLoader\n","        NeighborLoader that provides batches of data for evaluation.\n","\n","    Returns:\n","    -------\n","    float\n","        The average f1-score computed over all batches.\n","    \"\"\"\n","\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    total_pos_seen = 0\n","    with torch.no_grad():\n","        for batch in loader:\n","\n","            batch_size = batch.batch_size\n","            out = model(batch.x[:,:].to(torch.float32), batch.edge_index)[:batch_size]\n","            preds = out.argmax(dim=1)\n","            y = batch.y[:batch_size].view(-1).to(torch.long)\n","\n","            all_preds.append(preds.cpu().numpy())\n","            all_labels.append(y.cpu().numpy())\n","            total_pos_seen += (y.cpu().numpy()==1).sum()\n","\n","    all_preds = np.concatenate(all_preds)\n","    all_labels = np.concatenate(all_labels)\n","\n","    accuracy = accuracy_score(all_labels, all_preds)\n","    precision = precision_score(all_labels, all_preds, zero_division=0)\n","    recall = recall_score(all_labels, all_preds, zero_division=0)\n","    f1 = f1_score(all_labels, all_preds, zero_division=0)\n","    # roc_auc = roc_auc_score(all_labels, all_preds)\n","\n","    print(f\"\\nGNN Model Evaluation:\")\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","    print(f\"Precision: {precision:.4f}\")\n","    print(f\"Recall: {recall:.4f}\")\n","    print(f\"F1 Score: {f1:.4f}\")\n","    # print(f\"ROC AUC: {roc_auc:.4f}\")\n","    return f1"]},{"cell_type":"markdown","metadata":{"id":"6lpK_6Nd3WKC"},"source":["#### Define a function to compute validation loss GraphSAGE model"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"ARDfjgbV3WKC","executionInfo":{"status":"ok","timestamp":1747296700422,"user_tz":-420,"elapsed":42,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["def validation_loss(model, loader, criterion)->float:\n","    \"\"\"\n","    Computes the average validation loss for the GraphSAGE model.\n","\n","    Parameters:\n","    ----------\n","    model : torch.nn.Module\n","        The model for which the validation loss is calculated.\n","    loader : cugraph_pyg.loader.NeighborLoader\n","        NeighborLoader that provides batches of validation data.\n","    criterion : torch.nn.Module\n","        Loss function used to compute the loss between predictions and targets.\n","\n","    Returns:\n","    -------\n","    float\n","        The average validation loss over all batches.\n","    \"\"\"\n","    model.eval()\n","    with torch.no_grad():\n","        total_loss = 0\n","        batch_count = 0\n","        for batch in loader:\n","            batch_count += 1\n","            batch_size = batch.batch_size\n","            out = model(batch.x[:,:].to(torch.float32), batch.edge_index)[:batch_size]\n","            y = batch.y[:batch_size].view(-1).to(torch.long)\n","            loss = criterion(out, y)\n","            total_loss += loss.item()\n","    return total_loss / batch_count"]},{"cell_type":"markdown","metadata":{"id":"MMX48V9w3WKC"},"source":["\n","#### Define a function to train a XGBoost model"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"VQ7ew4e93WKC","executionInfo":{"status":"ok","timestamp":1747296700467,"user_tz":-420,"elapsed":38,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["from torch.utils.dlpack import to_dlpack\n","\n","def train_xgboost(embeddings, labels)->xgb.Booster:\n","    \"\"\"\n","    Trains an XGBoost classifier on the provided embeddings and labels.\n","\n","    Parameters:\n","    ----------\n","    embeddings : torch.Tensor\n","        The input feature embeddings for transaction nodes.\n","    labels : torch.Tensor\n","        The target labels (Fraud or Non-fraud) transaction, with the same length as the number of\n","        rows in `embeddings`.\n","\n","    Returns:\n","    -------\n","    xgboost.Booster\n","        A trained XGBoost model fitted on the provided data.\n","    \"\"\"\n","\n","    labels_cudf = cudf.Series(cp.from_dlpack(to_dlpack(labels)))\n","    embeddings_cudf = cudf.DataFrame(cp.from_dlpack(to_dlpack(embeddings)))\n","\n","    # Convert data to DMatrix format for XGBoost on GPU\n","    dtrain = xgb.DMatrix(embeddings_cudf, label=labels_cudf)\n","\n","    # Set XGBoost parameters for GPU usage\n","    param = {\n","        'max_depth': 6,\n","        'learning_rate': 0.2,\n","        'objective': 'binary:logistic',  # Binary classification\n","        'eval_metric': 'logloss',\n","        'tree_method': 'hist',  # Use GPU\n","        'device': 'cuda'\n","    }\n","\n","    # Train the XGBoost model\n","    bst = xgb.train(param, dtrain, num_boost_round=100)\n","\n","    return bst"]},{"cell_type":"markdown","metadata":{"tags":["parameters"],"id":"FlmVugp63WKC"},"source":["\n","#### Define a function to evaluate the XGBoost model\n"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"JWJspLR43WKC","executionInfo":{"status":"ok","timestamp":1747296701262,"user_tz":-420,"elapsed":818,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["from cuml.metrics import confusion_matrix\n","\n","def evaluate_xgboost(bst, embeddings, labels):\n","    \"\"\"\n","    Evaluates the performance of a XGBoost model by calculating different metrics.\n","\n","    Parameters:\n","    ----------\n","    bst : xgboost.Booster\n","        The trained XGBoost model to be evaluated.\n","    embeddings : torch.Tensor\n","        The input feature embeddings for transaction nodes.\n","    labels : torch.Tensor\n","        The target labels (Fraud or Non-fraud) transaction, with the same length as the number of\n","        rows in `embeddings`.\n","    Returns:\n","    -------\n","    A tuple containing f1-score, recall, precision, accuracy and the confusion matrix\n","    \"\"\"\n","\n","    # Convert embeddings to cuDF DataFrame\n","    embeddings_cudf = cudf.DataFrame(cp.from_dlpack(to_dlpack(embeddings)))\n","\n","    # Create DMatrix for the test embeddings\n","    dtest = xgb.DMatrix(embeddings_cudf)\n","\n","    # Predict using XGBoost on GPU\n","    preds = bst.predict(dtest)\n","    pred_labels = (preds > 0.5).astype(int)\n","\n","    # Move labels to CPU for evaluation\n","    labels_cpu = labels.cpu().numpy()\n","\n","    # Compute evaluation metrics\n","    accuracy = accuracy_score(labels_cpu, pred_labels)\n","    precision = precision_score(labels_cpu, pred_labels, zero_division=0)\n","    recall = recall_score(labels_cpu, pred_labels, zero_division=0)\n","    f1 = f1_score(labels_cpu, pred_labels, zero_division=0)\n","    roc_auc = roc_auc_score(labels_cpu, preds)\n","    conf_mat = confusion_matrix(labels.cpu().numpy(), pred_labels)\n","\n","    return f1, recall, precision, accuracy, conf_mat"]},{"cell_type":"markdown","metadata":{"id":"lBRpA34R3WKD"},"source":["#### Define a class to stop training once the model stops improving"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"4xroj9ld3WKD","executionInfo":{"status":"ok","timestamp":1747296701278,"user_tz":-420,"elapsed":15,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["class EarlyStopping:\n","    \"\"\"\n","    EarlyStopping class to halt training when a monitored metric stops improving.\n","\n","    Parameters:\n","    ----------\n","    patience : int, optional (default=10)\n","        The number of epochs with no improvement after which training will be stopped.\n","    min_delta : float, optional (default=0)\n","        The minimum change in the monitored metric to qualify as an improvement.\n","        If the change is smaller than `min_delta`, it is considered as no improvement.\n","    \"\"\"\n","    def __init__(self, patience=10, min_delta=0):\n","\n","        self.patience = patience\n","        self.min_delta = min_delta\n","        self.best_loss = float('inf')\n","        self.counter = 0\n","\n","    def check_early_stopping(self, val_loss):\n","\n","        if self.best_loss - val_loss > self.min_delta:\n","            self.best_loss = val_loss\n","            self.counter = 0  # Reset counter if there's an improvement\n","        else:\n","            self.counter += 1  # Increment counter if no improvement\n","\n","        if self.counter >= self.patience:\n","            return True\n","        return False"]},{"cell_type":"markdown","metadata":{"id":"iFpr0oke3WKD"},"source":["### Define a function to load data and create graph\n","* loads edges and create graph using cugraph-pyg\n","* loads preprocessed features associated with the graph nodes"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"kFtAkBM43WKD","executionInfo":{"status":"ok","timestamp":1747296701301,"user_tz":-420,"elapsed":21,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["def load_data(\n","    dataset_root : str,\n","    edge_filename: str = 'edges.csv',\n","    label_filename: str = 'labels.csv',\n","    node_feature_filename: str = 'features.csv',\n","    has_edge_feature: bool = False,\n","    edge_src_col: str = 'src',\n","    edge_dst_col: str = 'dst',\n","    edge_att_col: str = 'type'\n",") -> Tuple[\n","    Tuple[torch_geometric.data.FeatureStore, torch_geometric.data.GraphStore],\n","    Dict[str, torch.Tensor],\n","    int,\n","    int,\n","]:\n","    # Load the Graph data\n","    edge_path   = os.path.join(dataset_root, edge_filename)\n","    edge_data = cudf.read_csv(edge_path, header=None, names=[edge_src_col, edge_dst_col, edge_att_col], dtype=['int32','int32','float'])\n","\n","    num_nodes = max(edge_data[edge_src_col].max(), edge_data[ edge_dst_col].max()) + 1\n","    src_tensor = torch.as_tensor(edge_data[edge_src_col], device='cuda')\n","    dst_tensor = torch.as_tensor(edge_data[edge_dst_col], device='cuda')\n","\n","\n","\n","    graph_store = cugraph_pyg.data.GraphStore()\n","    graph_store[(\"n\", \"e\", \"n\"), \"coo\", False, (num_nodes, num_nodes)] = [src_tensor, dst_tensor]\n","\n","\n","    edge_feature_store = None\n","    if has_edge_feature:\n","        from cugraph_pyg.data import  TensorDictFeatureStore\n","        edge_feature_store = TensorDictFeatureStore()\n","        edge_attr = torch.as_tensor(edge_data[edge_att_col], device='cuda')\n","        edge_feature_store[(\"n\", \"e\", \"n\"), \"rel\"] = edge_attr.unsqueeze(1)\n","\n","\n","    del(edge_data)\n","\n","    # load the label\n","    label_path   = os.path.join (dataset_root, label_filename)\n","    label_data = cudf.read_csv(label_path, header=None, dtype=['int32'])\n","    y_label_tensor = torch.as_tensor(label_data['0'], device='cuda')\n","    num_classes = label_data['0'].unique().count()\n","\n","    wt_data = None\n","    if (args.use_cross_weights):\n","        if (args.cross_weights is None):\n","            num_labels_rows = label_data.size\n","            counts = label_data.value_counts()\n","            wt_data = torch.as_tensor(counts.sum()/counts, device='cuda', dtype=torch.float32)\n","            wt_data = wt_data/wt_data.sum()\n","\n","            if (num_classes > 2):\n","                wt_data = wt_data.T\n","        else:\n","            wt_data = torch.as_tensor(args.cross_weights, device='cuda')\n","\n","    del(label_data)\n","\n","    # load the features\n","    feature_path   = os.path.join(dataset_root, node_feature_filename)\n","    feature_data = cudf.read_csv(feature_path)\n","\n","    feature_columns = feature_data.columns\n","\n","    col_tensors = []\n","    for c in feature_columns:\n","        t = torch.as_tensor(feature_data[c].values, device='cuda')\n","        col_tensors.append(t)\n","\n","    x_feature_tensor = torch.stack(col_tensors).T\n","\n","\n","    feature_store = cugraph_pyg.data.TensorDictFeatureStore()\n","    feature_store[\"node\", \"x\"] = x_feature_tensor\n","    feature_store[\"node\", \"y\"] = y_label_tensor\n","\n","    num_features = len(feature_columns)\n","\n","    return (\n","        (feature_store, graph_store),\n","        edge_feature_store,\n","        num_nodes,\n","        num_features,\n","        num_classes,\n","        wt_data,\n","    )"]},{"cell_type":"code","source":["!pip install tensordict==0.2.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KVW7rTwh85z_","executionInfo":{"status":"ok","timestamp":1747296705628,"user_tz":-420,"elapsed":4325,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}},"outputId":"6af0bea3-e5e0-4304-aa2d-a60f155e20a3"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensordict==0.2.1 in /usr/local/lib/python3.11/dist-packages (0.2.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from tensordict==0.2.1) (2.6.0+cu124)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensordict==0.2.1) (2.0.2)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from tensordict==0.2.1) (3.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->tensordict==0.2.1) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->tensordict==0.2.1) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->tensordict==0.2.1) (3.0.2)\n"]}]},{"cell_type":"code","source":["from tensordict import TensorDict"],"metadata":{"id":"sU3F0RQW9k8J","executionInfo":{"status":"ok","timestamp":1747296705637,"user_tz":-420,"elapsed":7,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FsURwe179yMS","executionInfo":{"status":"ok","timestamp":1747296705757,"user_tz":-420,"elapsed":110,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}},"outputId":"e8a3ae18-4870-4507-843b-ada39457649c"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu May 15 08:11:45 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   64C    P0             28W /   70W |     102MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","+-----------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["data, ef_store, num_nodes, num_features, num_classes, cross_wt_data = load_data(args.dataset_root)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C1ewesUW8okX","executionInfo":{"status":"ok","timestamp":1747296707160,"user_tz":-420,"elapsed":1390,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}},"outputId":"c8c63e7f-bfdd-4d12-916d-ddbc34caad07"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/cugraph_pyg/data/__init__.py:27: FutureWarning: TensorDictFeatureStore is deprecated.  Consider changing your workflow to launch using 'torchrun' and store data in the faster and more memory-efficient WholeFeatureStore instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/cugraph_pyg/data/feature_store.py:67: UserWarning: Ignoring index parameter (attribute does not exist for group node)\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","metadata":{"id":"qZAYT9eZ3WKD"},"source":["\n","### Define a function to train the GraphSAGE model for particular values of hyper-parameters."]},{"cell_type":"code","execution_count":28,"metadata":{"id":"CDKHqTRo3WKF","executionInfo":{"status":"ok","timestamp":1747296724059,"user_tz":-420,"elapsed":68,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["def train_model_with_config(params, verbose=False):\n","\n","    data, ef_store, num_nodes, num_features, num_classes, cross_wt_data = load_data(args.dataset_root)\n","\n","    num_folds = params['n_splits']  # Number of folds\n","    fold_size = num_transaction_nodes // num_folds\n","\n","    # Perform cross-validation\n","    validation_losses = []\n","    for k in range(num_folds):\n","        training_nodes = torch.cat(\n","            (\n","                torch.arange(0, k * fold_size).unsqueeze(dim=0),\n","                torch.arange((k+1) * fold_size, num_transaction_nodes).unsqueeze(dim=0)\n","            ),\n","            dim=1\n","        ).squeeze(0)\n","\n","        validation_nodes = torch.arange(k * fold_size, (k+1) * fold_size)\n","\n","        # Create NeighborLoader for both training and testing (using cuGraph NeighborLoader)\n","        train_loader = NeighborLoader(\n","            data,\n","            num_neighbors=[args.fan_out, args.fan_out],\n","            batch_size=args.batch_size,\n","            input_nodes= training_nodes,\n","            shuffle=True\n","        )\n","\n","        # Use same graph but different seed nodes\n","        validation_loader = NeighborLoader(\n","            data,\n","            num_neighbors=[args.fan_out, args.fan_out],\n","            batch_size=args.batch_size,\n","            input_nodes= validation_nodes,\n","            shuffle=False\n","        )\n","\n","        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","        # Define the model\n","        model = GraphSAGE(\n","            in_channels=num_features,\n","            hidden_channels=params['hidden_channels'],\n","            out_channels=args.out_channels,\n","            n_hops=params['n_hops'],\n","            dropout_prob=0.25).to(device)\n","\n","\n","        # Define optimizer and loss function for GNN\n","        optimizer = torch.optim.Adam(model.parameters(),\n","                                    lr=params['learning_rate'],\n","                                    weight_decay=params['weight_decay'])\n","\n","        # criterion = torch.nn.CrossEntropyLoss(\n","        #     weight=cross_wt_data).to(device)  # Weighted loss function\n","\n","        criterion = torch.nn.CrossEntropyLoss(\n","            weight=torch.tensor([0.1, 0.9], dtype=torch.float32)).to(device)  # Weighted loss function\n","\n","        # Set up the early stopping object\n","        early_stopping = EarlyStopping(patience=3, min_delta=0.01)\n","\n","        best_val_loss = float('inf')\n","        num_epoch_for_best_loss = 0\n","\n","        # Train the GNN model\n","        for epoch in range(params['num_epochs']):\n","            train_loss = train_gnn(model, train_loader, optimizer, criterion)\n","            val_loss = validation_loss(model, validation_loader, criterion)\n","            if verbose:\n","                print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n","\n","            # Check early stopping criteria\n","            if early_stopping.check_early_stopping(val_loss):\n","                if verbose:\n","                    print(f\"Early stopping triggered at epoch {epoch+1}.\")\n","                break\n","\n","            # Save the best model based on validation loss\n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","                num_epoch_for_best_loss = epoch\n","        # Save validation loss for the current fold\n","        validation_losses.append(best_val_loss)\n","    return np.mean(validation_losses), model, num_epoch_for_best_loss"]},{"cell_type":"markdown","metadata":{"id":"7ldOSy-N3WKF"},"source":["\n","#### Parameter grid to search for better hyper-parameters\n","\n","__Note__: To execute the notebook faster, we commented out the grid search"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7IjJ5wh93WKF","executionInfo":{"status":"aborted","timestamp":1747296707167,"user_tz":-420,"elapsed":28,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["## Uncomment this cell to find the best hyperparameters in the parameter grid\n","# from sklearn.model_selection import ParameterGrid\n","# # Define the hyperparameter grid\n","# param_grid = {\n","#     'n_splits': [5],\n","#     'n_hops': [1, 2],\n","#     'learning_rate': [0.005, 0.01],\n","#     'hidden_channels': [32, 64],\n","#     'num_epochs': [8, 16],\n","#     'weight_decay': [1e-5],\n","\n","# }\n","# grid = list(ParameterGrid(param_grid))"]},{"cell_type":"markdown","metadata":{"id":"Fa9i6nep3WKF"},"source":["#### Search for better hyper-parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B-oOExG53WKG","executionInfo":{"status":"aborted","timestamp":1747296707170,"user_tz":-420,"elapsed":26,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["## Uncomment this cell to find the best hyperparameters in the parameter grid\n","# best_val_loss = float('inf')\n","# epoch = 0\n","# best_params = None\n","# for params in grid:\n","#     val_loss, _, epoch = train_model_with_config(params, verbose=False)\n","#     if val_loss < best_val_loss:\n","#         best_params = params\n","#         best_val_loss = val_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gEu6DBU33WKG","executionInfo":{"status":"aborted","timestamp":1747296707171,"user_tz":-420,"elapsed":17,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["# best_params"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"K36I7BKQ3WKJ","executionInfo":{"status":"ok","timestamp":1747296729799,"user_tz":-420,"elapsed":23,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["# Comment out this cell to train on new dataset\n","best_params = {\n","    'n_hops': 1,\n","    'learning_rate': 0.005,\n","    'hidden_channels': 32,\n","    'num_epochs': 16,\n","    'weight_decay': 1e-5,\n","}"]},{"cell_type":"markdown","metadata":{"id":"kI7bYAXy3WKJ"},"source":["#### Train and save the GraphSAGE model"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wkl2lobA3WKJ","executionInfo":{"status":"ok","timestamp":1747296749822,"user_tz":-420,"elapsed":18837,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}},"outputId":"d13c6cc6-afc3-40e6-bca6-879ea827bda6"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/cugraph_pyg/data/__init__.py:27: FutureWarning: TensorDictFeatureStore is deprecated.  Consider changing your workflow to launch using 'torchrun' and store data in the faster and more memory-efficient WholeFeatureStore instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/cugraph_pyg/data/feature_store.py:67: UserWarning: Ignoring index parameter (attribute does not exist for group node)\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Model saved at epoch 1 with training loss 0.2469.\n","Model saved at epoch 2 with training loss 0.1726.\n","Model saved at epoch 3 with training loss 0.1548.\n","Model saved at epoch 4 with training loss 0.1457.\n","Model saved at epoch 5 with training loss 0.1403.\n","Model saved at epoch 6 with training loss 0.1359.\n","Model saved at epoch 7 with training loss 0.1333.\n","Early stopping triggered at epoch 8.\n"]}],"source":["data, ef_store, num_nodes, num_features, num_classes, cross_wt_data = load_data(args.dataset_root)\n","\n","# Train on entire dataset\n","train_loader = NeighborLoader(\n","    data,\n","    num_neighbors=[args.fan_out, args.fan_out],\n","    batch_size=args.batch_size,\n","    input_nodes= torch.arange(num_transaction_nodes),\n","    shuffle=True\n",")\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Define the model\n","model = GraphSAGE(\n","    in_channels=num_features,\n","    hidden_channels=best_params['hidden_channels'],\n","    out_channels=args.out_channels,\n","    n_hops=best_params['n_hops'],\n","    dropout_prob=0.25).to(device)\n","\n","\n","# Define optimizer and loss function for GNN\n","optimizer = torch.optim.Adam(model.parameters(),\n","                            lr=best_params['learning_rate'],\n","                            weight_decay=best_params['weight_decay'])\n","\n","\n","criterion = torch.nn.CrossEntropyLoss(\n","    weight=torch.tensor([0.1, 0.9], dtype=torch.float32)).to(device)  # Weighted loss function\n","\n","# Set up the early stopping object\n","early_stopping = EarlyStopping(patience=3, min_delta=0.01)\n","\n","best_train_loss = float('inf')\n","\n","# Train the GNN model\n","\n","for epoch in range(best_params['num_epochs']):\n","    train_loss = train_gnn(model, train_loader, optimizer, criterion)\n","\n","    # Check early stopping criteria\n","    if early_stopping.check_early_stopping(train_loss):\n","        print(f\"Early stopping triggered at epoch {epoch+1}.\")\n","        break\n","\n","    # Save the best model based on validation loss\n","    if train_loss < best_train_loss:\n","        best_train_loss = train_loss\n","        if not os.path.exists(args.model_root_dir):\n","            os.makedirs(args.model_root_dir)\n","        torch.save(model, os.path.join(args.model_root_dir, 'node_embedder.pth'))\n","\n","        print(f\"Model saved at epoch {epoch+1} with training loss {best_train_loss:.4f}.\")"]},{"cell_type":"markdown","metadata":{"id":"QvItpeWJ3WKK"},"source":["### Train the XGBoost model based on embeddings produced by the GraphSAGE model"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s_YKzfcn3WKK","executionInfo":{"status":"ok","timestamp":1747296795566,"user_tz":-420,"elapsed":362,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}},"outputId":"b0c5d5f2-ec86-4824-831b-df28ab6ea07f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/cugraph_pyg/data/__init__.py:27: FutureWarning: TensorDictFeatureStore is deprecated.  Consider changing your workflow to launch using 'torchrun' and store data in the faster and more memory-efficient WholeFeatureStore instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/cugraph_pyg/data/feature_store.py:67: UserWarning: Ignoring index parameter (attribute does not exist for group node)\n","  warnings.warn(\n"]}],"source":["# NeighborLoader for training data\n","\n","data, ef_store, num_nodes, num_features, num_classes, cross_wt_data = load_data(args.dataset_root)\n","\n","train_loader = NeighborLoader(\n","    data,\n","    num_neighbors=[args.fan_out, args.fan_out],\n","    batch_size=args.batch_size,\n","    input_nodes= torch.arange(num_transaction_nodes),\n","    shuffle=True\n",")"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"Ccp_zNz23WKK","executionInfo":{"status":"ok","timestamp":1747296805564,"user_tz":-420,"elapsed":5192,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["# Set the device to GPU if available; otherwise, default to CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Extract embeddings from the second-to-last layer and keep them on GPU\n","embeddings, labels = extract_embeddings(model, train_loader)\n","\n","# Train an XGBoost model on the extracted embeddings (on GPU)\n","bst = train_xgboost(embeddings.to(device), labels.to(device))\n","\n","xgb_model_path = os.path.join(args.model_root_dir, 'embedding_based_xgb_model.json')\n","\n","if not os.path.exists(os.path.dirname(xgb_model_path)):\n","    os.makedirs(os.path.dirname(xgb_model_path))\n","\n","bst.save_model(xgb_model_path)"]},{"cell_type":"markdown","metadata":{"id":"bOcDykUr3WKL"},"source":["### Evaluation the model on unseen data"]},{"cell_type":"markdown","metadata":{"id":"lURcFGkd3WKL"},"source":["##### Load and prepare test data\n"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"-3rpFchN3WKL","executionInfo":{"status":"ok","timestamp":1747296810659,"user_tz":-420,"elapsed":289,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","test_path = os.path.join(args.dataset_base_path, 'xgb/test.csv')\n","test_data = cudf.read_csv(test_path)\n","\n","X = torch.tensor(test_data.iloc[:, :-1].values).to(torch.float32)\n","y = torch.tensor(test_data.iloc[:, -1].values).to(torch.long)"]},{"cell_type":"markdown","metadata":{"id":"XyfHAQeX3WKL"},"source":["##### Extract embeddings of the transactions using the GraphSAGE model"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"itZSsx8d3WKL","executionInfo":{"status":"ok","timestamp":1747296821122,"user_tz":-420,"elapsed":22,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"outputs":[],"source":["model.eval()\n","f1_value = 0.0\n","with torch.no_grad():\n","    test_embeddings = model(\n","        X.to(device), torch.tensor([[], []], dtype=torch.int).to(device), return_hidden=True)"]},{"cell_type":"markdown","metadata":{"id":"AEWYLuSg3WKL"},"source":["##### Evaluate the XGBoost model"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xtZhLgd53WKL","executionInfo":{"status":"ok","timestamp":1747296837168,"user_tz":-420,"elapsed":9663,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}},"outputId":"585cd8d5-b14d-4749-c71f-17a67af6fd28"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","XGBoost Evaluation:\n","Accuracy: 0.9488\n","Precision: 0.8013\n","Recall: 0.4772\n","F1 Score: 0.5982\n","Confusion Matrix: [[23778   247]\n"," [ 1091   996]]\n"]}],"source":["f1, recall, precision, accuracy, conf_mat = evaluate_xgboost(bst, test_embeddings, y)\n","\n","print(f\"\\nXGBoost Evaluation:\")\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")\n","print('Confusion Matrix:', conf_mat)"]},{"cell_type":"code","source":["!cp -r /content/data /content/drive/MyDrive/VNPT/"],"metadata":{"id":"rD9cZIEuA8XV","executionInfo":{"status":"ok","timestamp":1747297130623,"user_tz":-420,"elapsed":828,"user":{"displayName":"Khánh Hoàng Kim","userId":"09241777872923270644"}}},"execution_count":36,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}